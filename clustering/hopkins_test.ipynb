{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopkins test \n",
    "\n",
    "\n",
    "consensus clustering - especially if you do k means - consensus clusters - plus \n",
    "\n",
    "1. Load the dataset you want to test for clustering tendency.\n",
    "2. Normalize the dataset to ensure that all variables are on the same scale.\n",
    "3. Generate a random sample of the same size as the dataset.\n",
    "4. Calculate the distance between each point in the dataset and its nearest neighbor in the random sample.\n",
    "5. Calculate the distance between each point in the dataset and its nearest neighbor in the dataset.\n",
    "6. Calculate the Hopkins statistic as follows: 'H = D / (D + R)'  Where D is the sum of the distances between each point in the dataset and its nearest neighbor in the dataset, and R is the sum of the distances between each point in the dataset and its nearest neighbor in the random sample.\n",
    "7. Repeat steps 3 to 6 multiple times and calculate the average Hopkins statistic.\n",
    "8. Interpret the result. A value closer to 1 indicates that the dataset is suitable for clustering, while a value closer to 0.5 indicates that the dataset has no clustering structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import the packages needed \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "from scipy import linalg\n",
    "import sklearn\n",
    "from sklearn.datasets import make_blobs, make_circles, make_moons\n",
    "\n",
    "import plotly_express as px\n",
    "\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from numpy import random\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "import altair as alt\n",
    "np.random.seed(31)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data CSV file \n",
    "\n",
    "df=pd.read_csv('/rds/general/user/hg1222/home/Group5/matching/matched_data.csv', header=0, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### drop out the columns that are not needed \n",
    "df.drop(['cancer'], axis =1, inplace=True)\n",
    "df.drop(['X.1', 'X', 'eid'], axis =1, inplace=True)\n",
    "df.drop(['case_status', 'case_lymph', 'case_leuk'], axis =1, inplace=True)\n",
    "df.drop(['C_reactive_protein.0.0', 'Traff_int_major_rd.0.0', 'housing_score'], axis =1, inplace=True)\n",
    "df.drop(['Age_recr.0.0', 'Sex.0.0', 'BMI.0.0'], axis =1, inplace=True)\n",
    "df.drop(['Mood_swings.0.0', 'Smoking_status.0.0', 'Alc_drinker_status.0.0', 'health_score'], axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Lymphocyte_count.0.0  Monocyte_count.0.0  Reti_count.0.0  \\\n",
      "1                      2.60                0.50           0.074   \n",
      "2                      7.20                0.40           0.039   \n",
      "3                      1.90                0.40           0.067   \n",
      "4                      3.60                0.60           0.070   \n",
      "5                      7.00                0.55           0.040   \n",
      "...                     ...                 ...             ...   \n",
      "49295                  1.70                0.49           0.079   \n",
      "49303                  2.50                0.70           0.049   \n",
      "49310                  1.70                0.50           0.045   \n",
      "49316                  3.46                0.20           0.038   \n",
      "49336                  1.70                0.30           0.049   \n",
      "\n",
      "       WBC_count.0.0  RBC_count.0.0  Hgb_conc.0.0  Haematocrit_perc.0.0  \\\n",
      "1               8.10          4.920         14.20                 41.50   \n",
      "2              14.00          4.700         13.60                 40.80   \n",
      "3               5.60          4.390         13.80                 38.80   \n",
      "4              12.40          4.260         12.80                 36.30   \n",
      "5              12.45          4.220         14.03                 41.39   \n",
      "...              ...            ...           ...                   ...   \n",
      "49295           5.66          5.356         16.20                 47.67   \n",
      "49303           9.10          4.770         14.40                 43.30   \n",
      "49310           7.50          4.320         13.80                 39.30   \n",
      "49316           9.75          4.891         15.24                 44.57   \n",
      "49336           5.50          4.360         14.80                 42.80   \n",
      "\n",
      "       Platelet_count.0.0  Basophil_count.0.0  Eosinophil_count.0.0  \\\n",
      "1                   212.0                0.00                  0.30   \n",
      "2                   218.0                0.10                  0.30   \n",
      "3                   289.0                0.00                  0.10   \n",
      "4                   301.0                0.00                  0.20   \n",
      "5                   230.8                0.03                  0.27   \n",
      "...                   ...                 ...                   ...   \n",
      "49295               158.6                0.01                  0.37   \n",
      "49303               281.0                0.10                  0.60   \n",
      "49310               194.0                0.10                  0.20   \n",
      "49316               220.4                0.03                  0.13   \n",
      "49336               220.0                0.10                  0.10   \n",
      "\n",
      "       Neutrophil_count.0.0  Immature_ret_fraction.0.0  \\\n",
      "1                      4.60                      0.250   \n",
      "2                      6.00                      0.270   \n",
      "3                      3.10                      0.310   \n",
      "4                      7.80                      0.330   \n",
      "5                      4.60                      0.310   \n",
      "...                     ...                        ...   \n",
      "49295                  3.09                      0.225   \n",
      "49303                  5.20                      0.290   \n",
      "49310                  5.10                      0.300   \n",
      "49316                  5.93                      0.220   \n",
      "49336                  3.40                      0.230   \n",
      "\n",
      "       High_light_scatter_reti_count.0.0  \n",
      "1                                  0.019  \n",
      "2                                  0.011  \n",
      "3                                  0.021  \n",
      "4                                  0.023  \n",
      "5                                  0.012  \n",
      "...                                  ...  \n",
      "49295                              0.018  \n",
      "49303                              0.014  \n",
      "49310                              0.014  \n",
      "49316                              0.008  \n",
      "49336                              0.011  \n",
      "\n",
      "[14625 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the dataset\n",
    "df_normalized = (df - df.mean()) / df.std()\n",
    "\n",
    "# Set the number of iterations for Monte Carlo simulation\n",
    "n_iterations = 10\n",
    "\n",
    "# Initialize an array to store the Hopkins statistics\n",
    "hopkins_stats = np.zeros(n_iterations)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Generate a random sample of the same size as the dataset\n",
    "    random_sample = np.random.rand(df.shape[0], df.shape[1])\n",
    "\n",
    "    # Calculate the distance between each point in the dataset and its nearest neighbor in the random sample\n",
    "    distances_random = cdist(df_normalized, random_sample)\n",
    "    min_distances_random = distances_random.min(axis=1)\n",
    "\n",
    "    # Calculate the distance between each point in the dataset and its nearest neighbor in the dataset\n",
    "    distances = cdist(df_normalized, df_normalized)\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "    min_distances = distances.min(axis=1)\n",
    "\n",
    "    # Calculate the Hopkins statistic\n",
    "    D = np.sum(min_distances)\n",
    "    R = np.sum(min_distances_random)\n",
    "    H = D / (D + R)\n",
    "\n",
    "    # Store the Hopkins statistic for this iteration\n",
    "    hopkins_stats[i] = H\n",
    "\n",
    "# Calculate the average Hopkins statistic over all iterations\n",
    "average_hopkins_stat = np.mean(hopkins_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2786128389273824\n"
     ]
    }
   ],
   "source": [
    "print(average_hopkins_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of the Hopkins statistic\n",
    "std_dev_hopkins_stat = np.std(hopkins_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of Hopkins statistic: 0.0010801596833856493\n"
     ]
    }
   ],
   "source": [
    "print(\"Standard deviation of Hopkins statistic:\", std_dev_hopkins_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create an instance of the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Normalize the data\n",
    "df_normalized = scaler.fit_transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "np.random.seed(123)\n",
    "\n",
    "# Generate a random sample of the same size as the dataset\n",
    "n_samples = df_normalized.shape[0]\n",
    "random_sample = np.random.rand(n_samples, df_normalized.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Calculate the distance between each point in the dataset and its nearest neighbor in the random sample\n",
    "distances = cdist(df_normalized, random_sample)\n",
    "\n",
    "# Get the minimum distance for each point in the dataset\n",
    "min_distances = distances.min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75319491 0.72251812 0.68972137 ... 0.66386197 0.80089043 0.73909169]\n"
     ]
    }
   ],
   "source": [
    "print(min_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Calculate the distance between each point in the dataset and its nearest neighbor in the dataset\n",
    "distances = cdist(df_normalized, df_normalized)\n",
    "\n",
    "# Set the diagonal elements to a large value (e.g., infinity) so that they are not considered as nearest neighbors\n",
    "np.fill_diagonal(distances, np.inf)\n",
    "\n",
    "# Get the minimum distance for each point in the dataset\n",
    "min_distances = distances.min(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04381461 0.04918044 0.03204896 ... 0.06396959 0.03138194 0.03584128]\n"
     ]
    }
   ],
   "source": [
    "print(min_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Calculate the distance between each point in the dataset and its nearest neighbor in the random sample\n",
    "distances_random = cdist(df_normalized, random_sample)\n",
    "min_distances_random = distances_random.min(axis=1)\n",
    "\n",
    "# Calculate the distance between each point in the dataset and its nearest neighbor in the dataset\n",
    "distances = cdist(df_normalized, df_normalized)\n",
    "np.fill_diagonal(distances, np.inf)\n",
    "min_distances = distances.min(axis=1)\n",
    "\n",
    "# Calculate the Hopkins statistic\n",
    "D = np.sum(min_distances)\n",
    "R = np.sum(min_distances_random)\n",
    "H = D / (D + R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056869705505226326\n"
     ]
    }
   ],
   "source": [
    "print(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of the distances between each point in the dataset and its nearest neighbor in the dataset\n",
    "d = np.sum(min_distances)\n",
    "\n",
    "# Calculate the sum of the distances between each point in the dataset and its nearest neighbor in the random sample\n",
    "r = np.sum(np.min(distances, axis=1))\n",
    "\n",
    "# Calculate the Hopkins statistic\n",
    "h = d / (d + r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "\n",
    "# Normalize the dataset\n",
    "df_normalized = (df - df.mean()) / df.std()\n",
    "\n",
    "# Set the number of iterations for Monte Carlo simulation\n",
    "n_iterations = 10\n",
    "\n",
    "# Initialize an array to store the Hopkins statistics\n",
    "hopkins_stats = np.zeros(n_iterations)\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    # Generate a random sample of the same size as the dataset\n",
    "    random_sample = np.random.rand(df.shape[0], df.shape[1])\n",
    "\n",
    "    # Calculate the distance between each point in the dataset and its nearest neighbor in the random sample\n",
    "    distances_random = cdist(df_normalized, random_sample)\n",
    "    min_distances_random = distances_random.min(axis=1)\n",
    "\n",
    "    # Calculate the distance between each point in the dataset and its nearest neighbor in the dataset\n",
    "    distances = cdist(df_normalized, df_normalized)\n",
    "    np.fill_diagonal(distances, np.inf)\n",
    "    min_distances = distances.min(axis=1)\n",
    "\n",
    "    # Calculate the Hopkins statistic\n",
    "    D = np.sum(min_distances)\n",
    "    R = np.sum(min_distances_random)\n",
    "    H = D / (D + R)\n",
    "\n",
    "    # Store the Hopkins statistic for this iteration\n",
    "    hopkins_stats[i] = H\n",
    "\n",
    "# Calculate the average Hopkins statistic over all iterations\n",
    "average_hopkins_stat = np.mean(hopkins_stats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2791564795774287\n"
     ]
    }
   ],
   "source": [
    "print(average_hopkins_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test1]",
   "language": "python",
   "name": "conda-env-test1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
